{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oWm0zXecPh6"
      },
      "source": [
        "# lpcnet\n",
        "[![Generic badge](https://img.shields.io/badge/GitHub-packname-9cf.svg)][github]\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)][notebook]\n",
        "\n",
        "Author: [tarepan]\n",
        "\n",
        "[github]:https://github.com/tarepan/LPCNetTorch\n",
        "[notebook]:https://colab.research.google.com/github/tarepan/LPCNetTorch/blob/main/lpcnet.ipynb\n",
        "[tarepan]:https://github.com/tarepan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFQivUIyZyYi"
      },
      "source": [
        "## Colab Check\n",
        "Check environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cwyMoXOZ7e1"
      },
      "outputs": [],
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}' # Google Colaboratory runnning time\n",
        "!head -n 1 /proc/driver/nvidia/gpus/**/information                  # GPU type\n",
        "!/usr/local/cuda/bin/nvcc --version | sed '4!d'                     # CUDA version\n",
        "!python --version                                                   # Python version\n",
        "!pip show torch | sed '2!d'                                         # PyTorch version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K125Ein7VCwM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install tarepan/LPCNet for preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 0 - Install\n",
        "!apt install autoconf automake libtool\n",
        "!pip install git+https://github.com/tarepan/speechcorpusy.git\n",
        "!git clone https://github.com/tarepan/LPCNet.git\n",
        "%cd LPCNet\n",
        "!./download_model.sh\n",
        "\n",
        "# Step 1 - Env\n",
        "%env CFLAGS=-Ofast -g -march=native\n",
        "!echo $CFLAGS\n",
        "\n",
        "# Step 2 - Build\n",
        "!./autogen.sh    # Latest model download & `autoreconf`\n",
        "!./configure     # Run the generated configure script\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJCLLQ_8cPiM"
      },
      "source": [
        "Install the package from `tarepan/LPCNetTorch` public repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ9fU-17Sdxb"
      },
      "outputs": [],
      "source": [
        "# GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Dedicated dependencies install\n",
        "# !pip install \"torch==1.12.0\" -q      # Based on your PyTorch environment\n",
        "# !pip install \"torchaudio==0.12.0\" -q # Based on your PyTorch environment\n",
        "\n",
        "# repository install\n",
        "!pip uninstall lpcnet -y -q\n",
        "!pip install git+https://github.com/tarepan/LPCNetTorch -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import resampy\n",
        "from speechcorpusy import load_preset\n",
        "\n",
        "\n",
        "corpus = load_preset(\"Act100TKYM\", root=\"/content/gdrive/MyDrive/ML_data\")\n",
        "corpus.get_contents()\n",
        "all_utterances = corpus.get_identities()\n",
        "\n",
        "\n",
        "path_outfile = \"./train_pcm.s16\"\n",
        "sr_target = 16000\n",
        "\n",
        "with open(path_outfile, mode=\"ab\") as f:\n",
        "  for p in map(lambda item_id: corpus.get_item_path(item_id), all_utterances):\n",
        "\n",
        "    wave_int16, sr_source = sf.read(p, dtype='int16')\n",
        "    # todo: force mono\n",
        "    wave_int16_16k = resampy.resample(wave_int16, sr_source, sr_target)\n",
        "    # Append headless 16-bit PCM\n",
        "    wave_int16_16k.tofile(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!./dump_data -train train_pcm.s16 train_features.f32 train_waves.s16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptA8A-dhEgqZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKIasW5cTqhl"
      },
      "outputs": [],
      "source": [
        "# Launch TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/gdrive/MyDrive/ML_results/lpcnet/torch\n",
        "\n",
        "# Train\n",
        "!python -m lpcnet.main_train \\\n",
        "    train.ckpt_log.dir_root=/content/gdrive/MyDrive/ML_results/lpcnet/torch \\\n",
        "    train.ckpt_log.name_exp=2022 \\\n",
        "    train.ckpt_log.name_version=version_1 \\\n",
        "    data.adress_data_root=/content/gdrive/MyDrive/ML_data \\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lpcnet.main_inference \\\n",
        "    --model-ckpt-path=\"gdrive/MyDrive/ML_results/lpcnet/test2/default/version_0/checkpoints/last.ckpt\" \\\n",
        "    --i-path=\"./test.wav\" \\\n",
        "    --o-path=\"./o.wav\" \\\n",
        "    # --device=\"cpu\" --device=\"cuda:0\" \\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from lpcnet.model import Model\n",
        "\n",
        "\n",
        "# Configs\n",
        "model_ckpt_path = \"<ckpt.pt>\"\n",
        "device = \"cuda:0\" # \"cpu\"\n",
        "\n",
        "# Setup\n",
        "model: Model = Model.load_from_checkpoint(checkpoint_path=model_ckpt_path).to(torch.device(device)) # type: ignore ; because of PyTorch Lightning\n",
        "model.eval()\n",
        "\n",
        "# Inference\n",
        "with torch.inference_mode():\n",
        "    # Raw data\n",
        "    ####################################\n",
        "    ## From sample\n",
        "    raw = model.sample()\n",
        "    ####################################\n",
        "    ## From your file\n",
        "    # from pathlib import Path\n",
        "    # i_path = Path(f\"<your_data>.xxx\")\n",
        "    # raw = model.load(i_path)\n",
        "    ####################################\n",
        "    ## From your upstream data\n",
        "    # raw = <your_raw_data>\n",
        "    ####################################\n",
        "\n",
        "    batch = model.preprocess(raw, device)\n",
        "    o_pred = model.predict_step(batch, batch_idx=0)\n",
        "\n",
        "    # Tensor[Batch=1, ...] => Tensor[...] => NDArray[...]\n",
        "    o_wave = o_pred[0].to('cpu').numpy()\n",
        "\n",
        "# Output\n",
        "print(o_wave)\n",
        "##################################################\n",
        "# Audio\n",
        "##############################################\n",
        "## To File\n",
        "# import soundfile as sf\n",
        "# sf.write(...)\n",
        "##############################################\n",
        "## To Notebook\n",
        "# from IPython.display import Audio, display\n",
        "# display(Audio(o_wave, rate=o_sr))\n",
        "##############################################\n",
        "##################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O2DDaFlcPiX"
      },
      "outputs": [],
      "source": [
        "# # Usage stat\n",
        "# ## GPU\n",
        "# !nvidia-smi -l 3\n",
        "# ## CPU\n",
        "# !vmstat 5\n",
        "# !top"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lpcnet.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
